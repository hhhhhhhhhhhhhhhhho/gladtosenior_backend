"""
ì˜¤ë””ì˜¤ íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ì„œë¹„ìŠ¤

OpenAI Whisper APIë¥¼ ì‚¬ìš©í•˜ì—¬ ìŒì„± íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
10ë¶„ ì´ìƒì˜ ê¸´ ì˜¤ë””ì˜¤ íŒŒì¼ë„ ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
"""

import os
import asyncio
from pathlib import Path
from typing import Optional, List
from openai import AsyncOpenAI

# pydubëŠ” optional - ì—†ìœ¼ë©´ ê¸°ë³¸ ì²˜ë¦¬ë§Œ
try:
    from pydub import AudioSegment
    PYDUB_AVAILABLE = True
except ImportError:
    PYDUB_AVAILABLE = False
    print("âš ï¸ pydub ë¯¸ì„¤ì¹˜: ê¸´ ì˜¤ë””ì˜¤ íŒŒì¼ ë¶„í•  ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤.")


class AudioTranscriber:
    """
    ìŒì„± íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” íŠ¸ëœìŠ¤í¬ë¼ì´ë²„
    
    ê¸´ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì²­í¬ë¡œ ë¶„í• í•˜ì—¬ ì²˜ë¦¬í•˜ê³ ,
    ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ í†µí•©í•©ë‹ˆë‹¤.
    """
    
    # Whisper API ì œí•œ: 25MB ë˜ëŠ” ì•½ 10ë¶„
    MAX_CHUNK_DURATION_MS = 10 * 60 * 1000  # 10ë¶„ (ë°€ë¦¬ì´ˆ)
    OVERLAP_MS = 5000  # 5ì´ˆ ì˜¤ë²„ë© (ë¬¸ë§¥ ìœ ì§€)
    
    SUPPORTED_FORMATS = {'.mp3', '.mp4', '.mpeg', '.mpga', '.m4a', '.wav', '.webm', '.ogg', '.flac'}
    
    def __init__(self, api_key: Optional[str] = None, language: str = "ko"):
        """
        AudioTranscriber ì´ˆê¸°í™”
        
        Args:
            api_key: OpenAI API í‚¤ (ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜´)
            language: ì˜¤ë””ì˜¤ ì–¸ì–´ (ê¸°ë³¸ê°’: í•œêµ­ì–´)
        """
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            raise ValueError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        self.client = AsyncOpenAI(api_key=self.api_key)
        self.language = language
    
    def _validate_file(self, file_path: str) -> Path:
        """íŒŒì¼ ìœ íš¨ì„± ê²€ì‚¬"""
        path = Path(file_path)
        
        if not path.exists():
            raise FileNotFoundError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        
        if path.suffix.lower() not in self.SUPPORTED_FORMATS:
            raise ValueError(
                f"ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹ì…ë‹ˆë‹¤: {path.suffix}\n"
                f"ì§€ì› í˜•ì‹: {', '.join(self.SUPPORTED_FORMATS)}"
            )
        
        return path
    
    async def transcribe(self, file_path: str, show_progress: bool = True) -> str:
        """
        ì˜¤ë””ì˜¤ íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        
        Args:
            file_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            show_progress: ì§„í–‰ ìƒí™© ì¶œë ¥ ì—¬ë¶€
        
        Returns:
            ë³€í™˜ëœ í…ìŠ¤íŠ¸
        """
        path = self._validate_file(file_path)
        
        if show_progress:
            print(f"ğŸ¤ ì˜¤ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬ ì¤‘: {path.name}")
        
        # íŒŒì¼ í¬ê¸° í™•ì¸ (25MB ì œí•œ)
        file_size_mb = path.stat().st_size / (1024 * 1024)
        
        if file_size_mb > 25 and PYDUB_AVAILABLE:
            # í° íŒŒì¼ì€ ì²­í¬ ë¶„í•  ì²˜ë¦¬
            return await self._transcribe_large_file(path, show_progress)
        else:
            # ì‘ì€ íŒŒì¼ì€ ì§ì ‘ ì²˜ë¦¬
            return await self._transcribe_single_file(path, show_progress)
    
    async def _transcribe_single_file(self, path: Path, show_progress: bool) -> str:
        """ë‹¨ì¼ íŒŒì¼ íŠ¸ëœìŠ¤í¬ë¦½ì…˜"""
        if show_progress:
            print("   ğŸ”„ íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ì§„í–‰ ì¤‘...")
        
        with open(path, "rb") as audio_file:
            response = await self.client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                language=self.language,
                response_format="text",
            )
        
        if show_progress:
            print("   âœ… íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ì™„ë£Œ")
        
        return response
    
    async def _transcribe_large_file(self, path: Path, show_progress: bool) -> str:
        """í° íŒŒì¼ ì²­í¬ ë¶„í•  íŠ¸ëœìŠ¤í¬ë¦½ì…˜"""
        if not PYDUB_AVAILABLE:
            raise ImportError("pydubê°€ í•„ìš”í•©ë‹ˆë‹¤: pip install pydub")
        
        if show_progress:
            print("   ğŸ“¦ í° íŒŒì¼ - ì²­í¬ ë¶„í•  ì²˜ë¦¬ ì¤‘...")
        
        # ì˜¤ë””ì˜¤ ë¡œë“œ
        audio = AudioSegment.from_file(str(path))
        duration_ms = len(audio)
        
        if show_progress:
            print(f"   â±ï¸ ì´ ê¸¸ì´: {duration_ms / 60000:.1f}ë¶„")
        
        # ì²­í¬ ë¶„í• 
        chunks = self._split_audio(audio)
        
        if show_progress:
            print(f"   ğŸ“¦ {len(chunks)}ê°œì˜ ì²­í¬ë¡œ ë¶„í• ")
        
        # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
        temp_dir = Path(path.parent) / ".temp_audio"
        temp_dir.mkdir(exist_ok=True)
        
        try:
            # ì²­í¬ë³„ íŠ¸ëœìŠ¤í¬ë¦½ì…˜
            tasks = []
            for i, chunk in enumerate(chunks):
                tasks.append(self._transcribe_chunk(chunk, i, temp_dir))
            
            if show_progress:
                print("   ğŸ”„ íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ì§„í–‰ ì¤‘...")
            
            results = await asyncio.gather(*tasks)
            
            if show_progress:
                print("   âœ… íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ì™„ë£Œ")
            
            # ê²°ê³¼ í†µí•©
            return "\n\n".join(results)
            
        finally:
            # ì„ì‹œ ë””ë ‰í† ë¦¬ ì‚­ì œ
            if temp_dir.exists():
                import shutil
                shutil.rmtree(temp_dir, ignore_errors=True)
    
    def _split_audio(self, audio) -> List:
        """ê¸´ ì˜¤ë””ì˜¤ë¥¼ ì²­í¬ë¡œ ë¶„í• """
        duration_ms = len(audio)
        
        if duration_ms <= self.MAX_CHUNK_DURATION_MS:
            return [audio]
        
        chunks = []
        start_ms = 0
        
        while start_ms < duration_ms:
            end_ms = min(start_ms + self.MAX_CHUNK_DURATION_MS, duration_ms)
            chunk = audio[start_ms:end_ms]
            chunks.append(chunk)
            start_ms = end_ms - self.OVERLAP_MS
            
            if duration_ms - start_ms < self.OVERLAP_MS * 2:
                break
        
        return chunks
    
    async def _transcribe_chunk(self, chunk, chunk_index: int, temp_dir: Path) -> str:
        """ë‹¨ì¼ ì²­í¬ íŠ¸ëœìŠ¤í¬ë¦½ì…˜"""
        temp_file = temp_dir / f"chunk_{chunk_index}.mp3"
        chunk.export(str(temp_file), format="mp3")
        
        try:
            with open(temp_file, "rb") as audio_file:
                response = await self.client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio_file,
                    language=self.language,
                    response_format="text",
                )
            return response
        finally:
            if temp_file.exists():
                temp_file.unlink()
    
    def transcribe_sync(self, file_path: str, show_progress: bool = True) -> str:
        """ë™ê¸° ë°©ì‹ íŠ¸ëœìŠ¤í¬ë¦½ì…˜ (í¸ì˜ ë©”ì„œë“œ)"""
        return asyncio.run(self.transcribe(file_path, show_progress))


async def transcribe_audio_file(file_path: str, language: str = "ko") -> str:
    """ì˜¤ë””ì˜¤ íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” í¸ì˜ í•¨ìˆ˜"""
    transcriber = AudioTranscriber(language=language)
    return await transcriber.transcribe(file_path)
